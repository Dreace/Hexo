---
title: '[Python] 简单的堆糖合辑下载器'
tags:
  - Python
  - 代码
  - 堆糖
  - 爬虫
typora-root-url: ../../source/
url: 280.html
id: 280
categories:
  - Python
  - 爬虫
date: 2018-03-25 13:32:47
---

\[title\]功能描述\[/title\]

*   自动下载合辑内所有图片
*   多进程下载

\[title\]不足\[/title\]

*   无进度显示

\[title\]代码\[/title\]

\# -*- coding: utf-8 -*-
"""
Created on Sun Aug 06 22:52:47 2017

@author: Dreace
"""

import urllib2
import ssl
import json
import os
import re
import sys
import time
import random
import traceback
from multiprocessing.dummy import Pool as ThreadPool

ssl.\_create\_default\_https\_context = ssl.\_create\_unverified_context
s = sys.exc_info()


class JSONObject:
    def \_\_init\_\_(self, d):
        self.\_\_dict\_\_ = d


dir_ = ""
count = 0
error = 0


def start():
    global dir_
    dir_ = os.getcwd()  # 存储当前工作目录
    url = raw_input(u'请输入链接：')
    reobj = re.search(r'id=(\[0-9\]{0,})', url, re.M | re.I)  # 从链接中提取专辑ID
    try:
        id_ = reobj.groups(1)\[0\]
        infos = get\_info(id\_)
        print u'专辑ID:' + infos\[0\]
        print u'总图片数：' + str(infos\[1\])
        if os.path.exists(infos\[0\]) == False:
            os.makedirs(infos\[0\])  # 根据专辑ID创建目录
        else:
            switch = raw_input(u'该专辑已经下载过，是否重复下载？（Y/N）')
            if switch == 'y' or switch == 'Y':
                pass
            else:
                print(u'已终止下载！')
                return
        os.chdir(infos\[0\])  # 改变工作目录
    except Exception, e:
        print u'不能获取专辑信息，请重新输入'
        print u'发生错误：' + str(e)
        # traceback.print_exc()
    get_img(infos)


def get\_info(id\_):
    try:
        infos = \["", ""\]
        infos\[0\] = id_
        url = "https://www.duitang.com/napi/blog/list/by\_album/?album\_id=" + id_ + "&limit=1&start=1"  # 获取专辑中图片数量
        response = urllib2.urlopen(url)
        json_file = response.read()
        data = json.loads(json\_file, object\_hook=JSONObject)  # 有json创建一个Python对象
        infos\[1\] = data.data.total  # 获取图片总数
        return infos
    except Exception, e:
        print str(e)


def get_img(infos):
    start_time = time.time()  # 计时用
    # count = infos\[1\]/20
    urls = \[\]
    i = 0
    while (i <= infos\[1\]):
        url_ = "https://www.duitang.com/napi/blog/list/by\_album/?album\_id=%s&limit=20&start=%d&_=" % (infos\[0\], i)  #
        urls.append(url_)
        # print url_
        i = i + 20
    print u"图片保存在%s" % (os.getcwd())
    print u"开始下载！n"
    pool = ThreadPool(16)  # 设置进程数量
    pool.map(download_img, urls)  # 开启线程
    pool.close()
    pool.join()
    os.chdir(dir_)  # 更改运行目录
    print u"下载完成！"
    print u"成功下载%d张图片,共计发生%d个错误" % (count, error)
    print u"耗时%ds" % (time.time() - start_time)


def download_img(url):
    global count
    global error
    flag = True
    i = 0
    time.sleep(random.uniform(0.5, 2.0))
    while (flag):
        try:
            response = urllib2.urlopen(url + str(time.time()), timeout=5)
            json_file = response.read()
            data = json.loads(json\_file, object\_hook=JSONObject)
            for img\_list in data.data.object\_list:
                # url = img_list.photo.path
                img\_response = urllib2.urlopen(img\_list.photo.path, timeout=5)  # 下载图片
                img\_file = img\_response.read()
                file_ = open(str(img\_list.add\_datetime_ts) + ".jpg", "wb")  # 保存图片
                file_.write(img_file)
                file_.close()
                count = count + 1
                flag = False
        except Exception, e:
            # print u'发生错误:%s'%(str(e))
            # traceback.print_exc()
            error = error + 1
            i = i + 1
        if i == 3:  # 重试三次若还是超时就退出
            flag = False


if \_\_name\_\_ == '\_\_main\_\_':
    try:
        start()
    except Exception, e:
        print str(e)